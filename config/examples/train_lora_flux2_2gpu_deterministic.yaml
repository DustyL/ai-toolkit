---
# FLUX.2 LoRA Training Configuration - 2 GPU Deterministic Split
#
# This configuration demonstrates deterministic GPU splitting for FLUX.2 training
# across 2 GPUs. The deterministic split ensures consistent memory distribution
# and predictable behavior across runs.
#
# FLUX.2 Architecture:
#   - 8 double blocks (DoubleStreamBlock): Process image and text streams separately
#   - 48 single blocks (SingleStreamBlock): Process concatenated img+txt stream
#
# Default 2-GPU Split (even distribution):
#   - GPU 0: 4 double blocks + 24 single blocks + embedders/output layers
#   - GPU 1: 4 double blocks + 24 single blocks
#
# Memory estimate per GPU with BF16: ~50GB transformer + text encoder on GPU 0

job: extension
config:
  name: "flux2_lora_2gpu_deterministic"
  process:
    - type: 'sd_trainer'
      training_folder: "output"
      device: cuda:0  # Primary device, splitter distributes to all GPUs

      # Trigger word handling
      # trigger_word: "p3r5on"

      network:
        type: "lora"
        linear: 16
        linear_alpha: 16

      save:
        dtype: float16
        save_every: 500
        max_step_saves_to_keep: 3

      datasets:
        - folder_path: "/path/to/images/folder"
          caption_ext: "txt"
          caption_dropout_rate: 0.05
          shuffle_tokens: false
          cache_latents_to_disk: true
          resolution: [512, 768, 1024]

      train:
        batch_size: 1
        steps: 3000
        gradient_accumulation_steps: 1
        train_unet: true
        train_text_encoder: false
        gradient_checkpointing: false  # Disabled - GPU split provides memory relief
        noise_scheduler: "flowmatch"
        optimizer: "adamw8bit"
        lr: 1e-4
        dtype: bf16

        ema_config:
          use_ema: true
          ema_decay: 0.99

      model:
        name_or_path: "black-forest-labs/FLUX.2-dev"
        arch: "flux2"  # Uses is_flux2: true internally
        quantize: true

        # Enable GPU splitting across all available GPUs
        split_model_over_gpus: true

        # Deterministic split uses defaults for 2 GPUs:
        # gpu_split_double: [4, 4]    # 4 double blocks per GPU (sum=8)
        # gpu_split_single: [24, 24]  # 24 single blocks per GPU (sum=48)

      sample:
        sampler: "flowmatch"
        sample_every: 500
        width: 1024
        height: 1024
        prompts:
          - "a professional photo of a woman with red hair"
          - "a landscape photograph of mountains at sunset"
          - "a detailed portrait of a man in a business suit"
        neg: ""
        seed: 42
        walk_seed: true
        guidance_scale: 4
        sample_steps: 20

meta:
  name: "[name]"
  version: '1.0'
  description: "FLUX.2 LoRA training with deterministic 2-GPU split"
  gpu_config:
    num_gpus: 2
    split_type: "deterministic_default"
    double_blocks_per_gpu: [4, 4]
    single_blocks_per_gpu: [24, 24]
